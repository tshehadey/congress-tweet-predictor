{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(convention_cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party \n",
    "                            FROM conventions\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    convention_data.append([row[0], row[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['One special memory from that trip is of a young boy I had the privilege of visiting while at Bambino Gesu Hospital in Rome, Italy. While there, I read a little boy a story and learned that he and his family had been waiting for a heart for a very long time, and he had a grim prognosis. His situation brought my staff and me to tears, and we spoke of a little ELLs as we flew to Belgium for the next part of our trip. Upon landing just a few hours later, we learned that a heart had been donated and would be going to the little one. I think about him often, along with so many amazing and strong young patients across our own country.',\n",
       "  'Republican'],\n",
       " ['We’ll work to meet our extraordinary challenges because progress is made by the hopeful, not the cynical. And we will do that work together because movements are built by the many, not the few.',\n",
       "  'Democratic'],\n",
       " ['I am one of a handful of people living today who have seen firsthand the immense weight and awesome power of the presidency. And let me once again, tell you this, the job is hard. It requires clear- headed judgment, a mastery of complex and competing issues, a devotion to facts and history, a moral compass, and an ability to listen. And an abiding belief that each of the 330 million lives in this country has meaning and worth.',\n",
       "  'Democratic'],\n",
       " ['Yeah, every day.', 'Democratic'],\n",
       " ['We’ve committed to a renewable energy future with exciting and fulfilling careers for workers all across our beautiful state, including right here in the heart of Northern New Mexico. We’re laying a roadmap here for what America can and should look like in the 21st century.',\n",
       "  'Democratic'],\n",
       " ['They’ll rescue the economy like Joe helped me do after the great recession. I asked him to manage the Recovery Act, which jump-started the longest stretch of job growth in history. And he sees this moment now, not as a chance to get back to where we were, but to make long overdue changes so that our economy actually makes life a little easier for everybody. Whether it’s the waitress trying to raise a kid on her own or the shift worker, always on the edge of getting laid off or the student figuring out how to pay for next semester’s classes. Joe and Kamala will restore our standing in the world. And as we’ve learned from this pandemic that matters.',\n",
       "  'Democratic'],\n",
       " ['It all started at a tea party. 13 years before the American Civil War, civil unrest and division separated countrymen into two opposing camps, one determined to keep African-American people enslaved. The other, determined to see all people free. Elizabeth Cady Stanton and Lucretia Mott felt the call to fight for that freedom, when they were selected as delegates for an anti-slavery convention. But, upon arrival, were told they could not speak or vote at the male-dominated event. On July 9th, 1848, Mott, Stanton, and three other women met for tea. By the end of the day, they’d formed a coalition with the sole purpose of gaining the right for women to vote, so they in turn would be free to fight for the freedoms of others. Women across America united and formed activist groups, working tirelessly to win the vote for American women. The unconquerable Susan B. Anthony became one of the most visible leaders of women’s suffrage, when in 1872, she registered and voted for every Republican on the ballot.',\n",
       "  'Republican'],\n",
       " ['I attended North Carolina Central University, a historical black college. For generations, HBCUs have been the incubators that developed black scholars and math and science and religion, engineering and politics. They have been important springboards for the black success, but Democrats haven’t treated them that way. When President Trump took office, he changed everything. He delivered historic funding to HBCUs and he guaranteed it for 10 years. Something that has never happened in the history of this country. That gave our HBCUs stability, the chance to grow and produce the next generation of black leaders. That’s right. Donald Trump did that.',\n",
       "  'Republican'],\n",
       " ['Michigan auto workers are the best in the world, but we’d be nowhere without Joe Biden, and a lot of folks wanted to let Detroit go bankrupt, but Joe Biden believed in us, and together, we fought to save our auto industry.',\n",
       "  'Democratic'],\n",
       " ['I think there’s a political realignment that’s taking place. I’ve always been very anti-war and now Trump is by a mile the anti-war candidate. I’ve always been very much for free speech, Trump is now by a mile the more pro-free speech candidate.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2891 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    ret_dict = dict()\n",
    "    for word in text.lower().split():\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gave', 'You’re', 'travel', 'alone', 'join', 'goodness', 'Lady', 'pray.', 'safe,', 'amendment']\n",
      "{'is': True, 'great': True}\n",
      "{'the': True, 'people': True, 'love': True, 'freedom': True}\n"
     ]
    }
   ],
   "source": [
    "assert(len(feature_words) > 0)\n",
    "print(list(feature_words)[:10])\n",
    "print(conv_features(\"america is great\", feature_words))\n",
    "print(conv_features(\"the people love freedom\", feature_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                freedom, = True           Republ : Democr =     13.4 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                freedom. = True           Republ : Democr =     11.5 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "                 special = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                  dream, = True           Republ : Democr =     10.9 : 1.0\n",
      "              education, = True           Republ : Democr =     10.9 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.5 : 1.0\n",
      "                   armed = True           Republ : Democr =      9.9 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "              greatness. = True           Republ : Democr =      9.9 : 1.0\n",
      "                 liberal = True           Republ : Democr =      9.9 : 1.0\n",
      "                veterans = True           Republ : Democr =      9.9 : 1.0\n",
      "               wonderful = True           Republ : Democr =      9.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "I do find it interesting, but not surprising, that variations of words like freedom are listed multiple times and are heavily used by republicans. I also find it humorous that the word \"liberal\" is mentioned for the republicans but conservative is not mentioned here for democrats. It hints at how republicans use the word liberal as a tool in swaying their audience. Words like \"preserve\", \"armed\", and \"greatness\" all show the ideologies that republicans push for in their speeches as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for row in results:\n",
    "    tweet = row[2].lower()\n",
    "    party = row[1]\n",
    "    tweet_data.append([tweet, party])\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: b'earlier today, i spoke on the house floor abt protecting health care for women and praised @ppmarmonte for their work on the central coast. https://t.co/wqgtrzt7vv'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'go tribe! #rallytogether https://t.co/0nxutfl9l5'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"apparently, trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #trumpbudget https://t.co/ckyqo5t0qh\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'we\\xe2\\x80\\x99re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\\n\\nhttps://t.co/ezpv0vmiz3'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'let\\xe2\\x80\\x99s make it even greater !! #kag \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 https://t.co/y9qozd5l2z'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"we have about 1hr until the @cavs tie up the series 2-2. i'm #allin216 @repbarbaralee you scared? #roadtovictory\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'congrats to @belliottsd on his new gig at sd city hall. we are glad you will continue to serve\\xe2\\x80\\xa6 https://t.co/fkvmw3cqdi'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'we are really close, we have over $3500 raised toward the match right now. whoot!! (that\\xe2\\x80\\x99s $7000 for the non-math majors in the room \\xf0\\x9f\\x98\\x82). help us get there https://t.co/tu34c472sd https://t.co/qsdqkypsmc'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'today, the comment period for @potus\\xe2\\x80\\x99s plan to expand offshore drilling opened to the public. you have 60 days (until march 9) to share why you oppose the proposed program directly with the trump administration. comments can be made by email or mail. https://t.co/baaymejxqn'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'celebrated @icseastla\\xe2\\x80\\x99s 22 years of eastside commitment &amp; saluted community leaders at last night\\xe2\\x80\\x99s awards dinner! https://t.co/7v7gh8givb'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = estimated_party = classifier.classify(features)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 4372}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 5630})})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The model classified all text as being democratic and did not classify any text as republican. The model is heavily biased toward democratic language and did not properly run. As shown by the code below, there is about 100,000 more tweets for democrats than republicans and is likely skewing the classifier's learning. Rebalancing the data to be even and re-running the model would help alleviate the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Democratic': 376125, 'Republican': 288531})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([label for _, label in tweet_data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
